---
title: "Bayesian inference"
subtitle: "Introduction"
author: "Ihnwhi Heo"
date: 'January 22, 2021'
output: 
  ioslides_presentation:
    widescreen: true
    smaller: true
    logo: Utrecht-Logo.png
bibliography: references.bib
---

```{r setup, include=FALSE}
require(DiagrammeR)
require(plotly)
require(lavaan)
require(DT)
set.seed(322)
df <- data.frame(x <- rnorm(1000, 2, 15))
p <- ggplot(df, aes(x)) + 
  geom_density(alpha = 0.3, position = "stack") + 
  ggtitle("A prior distribution")
```

## About the presenter

My name is Ihnwhi Heo. If you are interested in knowing me, see <https://ihnwhiheo.github.io>.

## Three main componenets of Bayesian inference

- Likelihood
- Prior distribution
- Posterior distribution

## True data-generating mechanism

<center>
<img src = "true-dat.png" width = 40% />
</center>

## Formula for Posterior model probability and Bayes factor

- Posterior model probability

$$
 p(\mathcal{M}_{i}|data) = 
 \frac{
 p(data|\mathcal{M}_{i})
 p(\mathcal{M}_{i})
 }
 {
 \sum_{j=1}^{n}p(data|{\mathcal{M}}_{j})p(\mathcal{M}_{j})
 }
$$

- Bayes factor

$$
 \frac{p(\mathcal{M}_{1}|data)}{p(\mathcal{M}_{2}|data)} = 
 \frac
  {\frac{p(data|\mathcal{M}_{1})p(\mathcal{M}_{1})}
  {\sum_{j=1}^{n}p(data|{\mathcal{M}}_{j})p(\mathcal{M}_{j})}}
  {\frac{p(data|\mathcal{M}_{2})p(\mathcal{M}_{2})}
  {\sum_{j=1}^{n}p(data|{\mathcal{M}}_{j})p(\mathcal{M}_{j})}} =
  \frac{p(data|\mathcal{M}_{1})}{p(data|\mathcal{M}_{2})}
 \times 
 \frac{p(\mathcal{M}_{1})}{p(\mathcal{M}_{2})}
$$

## Prior distributions

```{r, echo=FALSE}
ggplotly(p)
```

## Tables

```{r}
datatable(PoliticalDemocracy, options = list(pageLength = 6))
```

## Citation

See @heo2020advanced; @heo2020jasp for tutorials.
